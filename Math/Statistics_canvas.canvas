{
	"nodes":[
		{"id":"669ed70db2f66147","type":"text","text":"### L2. \n\n**2.1 Статистики и оценки**\n\n$(E, \\mathcal{E})$ - измеримое. $S: \\mathcal{X}^n \\rightarrow E$ - статистика\n$E = \\mathcal{\\Theta}$, то $S(X)$ - оценка $\\theta$\n\n1) Выборочные характеристики\n- $\\bar{g}(x) = \\frac{1}{n} \\sum_{i=1}^n g(X_i)$\n- $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$ - выборочное среднее\n- $\\bar{x}^k = \\frac{1}{n} \\sum_{i=1}^n x_i^k$ - выборочный $k$-й момент\n2) Функции от выборочных характеристик\n- $h(\\bar{g}_1(x), ..., \\bar{g}_k(x))$\n\tEx. $g_1(x) = x^2, g_2(x) = x, h(x,y) = x - y^2 \\Rightarrow h = \\bar{x^2} - \\bar{x}^2 = S^2 (= \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2$\n3) Порядковые статистики $X_{(k)}$\n\n**2.2 Свойства оценок**\n\n- $\\hat{\\theta}(X)$ - несмещённая оценка $\\tau(\\theta)$. если $E_{\\theta}(X) = \\tau(\\theta)$ (среднее значение оценки при данном истинном значении параметра даёт $\\tau(\\theta)$)\nEx. $\\mathcal{P} = \\lbrace \\textrm{Exp}(\\theta) | \\theta > 0\\rbrace$. $\\bar{X}, X_1$ - несмещённые оценки $1 / \\theta$: \n$$ E_\\theta \\bar{X} = E_\\theta \\frac{1}{n}\\sum_{i=1}^n X_i = \\frac{1}{n} \\sum_{i=1}^n E_\\theta X_i = E_\\theta X_1 = 1/\\theta$$\n- $\\hat{\\theta}(X_1, ..., X_n)$ (сильно) состоятельная оценка $\\theta$, если $\\hat{\\theta}(X_1, ..., X_n) \\xrightarrow{P_\\theta \\ (п.н.)} \\theta$\nСмысл: при больших $n$ вероятность большого отклонения $\\hat{\\theta}$ от $\\theta$ мала \n- $\\hat{\\theta}(X_1, ..., X_n)$ асимптотически нормальная оценка $\\theta$, если \n$$\\sqrt{n} (\\hat{\\theta}(X_1, ..., X_n) - \\theta) \\xrightarrow{d_\\theta} N(0, \\Sigma(\\theta))$$\n$d = 1 \\Rightarrow \\Sigma(\\theta) = \\sigma^2(\\theta)$\nСмысл: при больших $n$ $\\hat{\\theta} \\sim N(\\theta, \\sigma^2(\\theta)/n)$\n\nУтв. Сильная состоятельность / асимптотическая нормальность $\\Rightarrow$ состоятельность\nУтв. $X_1, ...$ выборка т.ч. $E_\\theta|X_1|^{2k}<+\\infty$, тогда $\\bar{X^k}$ - несмещённая, сильно состоятельная, а.н. оценка $E_\\theta X_1^k$\n\n**2.3. Наследование свойств**","x":480,"y":-21,"width":680,"height":1101},
		{"id":"4f7d0e0913c48c5d","type":"text","text":"### L1.\n\n**Однократный эксперимент**\n\n$\\mathcal{X}$ - **выборочное пространство**\n$\\mathcal{B}_\\mathcal{X}$ - $\\sigma$-алгебра на $\\mathcal{X}$\n$\\mathcal{P}$ - семейство распределений\n$(\\mathcal{X}, \\mathcal{B}_\\mathcal{X}, \\mathcal{P})$ - **вероятностно-статистическое пространство**, \n$X: \\mathcal{X} \\rightarrow \\mathcal{X}$ - наблюдаемая\n\n**Многократный эксперимент**\n$(\\mathcal{X}^n, \\mathcal{B}_{\\mathcal{X}^n}, \\mathcal{P}^n)$\n$X^i: \\mathcal{X}^n \\rightarrow \\mathcal{X}$ - наблюдение, соотвествующее i-му эксперименту\n\n**Бесконечный эксперимент**\n$(\\mathcal{X}^\\infty, \\mathcal{B}_{\\mathcal{X}^\\infty}, \\mathcal{P}^\\infty)$\n$X_i: \\mathcal{X}^\\infty \\rightarrow \\mathcal{X}$\n\n**Виды подходов к статистике**\n1) Параметрический: $P \\in \\{ \\mathcal{P}_\\theta | \\theta \\in \\Theta \\}$\nEx. $X_1, ..., X_n \\sim \\textrm{Exp}(\\theta)$: $\\mathcal{X} = (0, +\\infty)$, $P \\in \\{ \\textrm{Exp}(\\theta) | \\theta > 0\\}$\n2) Непараметрический\n\nПо способу вывода:\n3) Частотный\n4) Байесовский\n\n","x":-80,"y":-21,"width":560,"height":1101},
		{"id":"757297f351696917","type":"text","text":"### S1.\n\nТВ vs. МС: в ТВ даны случайные величины, нужно что-то посчитать о них, в МС даны измерения, нужно что-то сказать о породившей их случайной величине. Нужно дать оценку и обосновать, почему оценка заслуживает использования \n\n**1.** Пусть известно, что $\\xi \\in \\textrm{Be}(p)$. $X_i$ - результат $i$-го броска.\nОценка параметра $p$: $\\hat{p} = \\sum_{i=1}^n X_i$. Тогда:\n$$E\\hat{p} = p, \\ D\\hat{p} = \\frac{p(1-p)}{n} \\rightarrow 0$$\nУЗБЧ:\n$$\\frac{1}{n} \\sum_{i=1}^n X_i \\xrightarrow{п.н.} E(\\frac{1}{n}\\sum_i X_i) = p$$\n**2.** $\\xi$, $F_\\xi(x)$ \n$X_1, ..., X_n$ - выборка, независимы в совокупности => простая\n$T(X)$ - статистика\n$F_\\xi(x) = F_{X_i}(x)$\nЭмпирическая ф.р. (случайная функция):\n$$\\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n I(x_i < x)$$\n1) $0 \\leq \\hat{F}_n(x) \\leq 1$\n2) $n\\hat{F}_n(x) \\in Bi(n, F_\\xi(x))$\n3) $E\\hat{F}_n(x) = F_\\xi(x)$\n4) $D\\hat{F}_n(x) = 1/n F_\\xi(x)(1 - F_\\xi (x)) \\rightarrow_{n \\rightarrow \\infty} 0$\n5) $\\hat{F}_n(x) \\xrightarrow{P, п.н.}_{n \\rightarrow \\infty} F_\\xi(x)$ в каждой точке $x \\in \\mathbb{R}$\n6) $$\\frac{n \\hat{F}_n(x) - nF_\\xi(x)}{\\sqrt{n F_\\xi(x)(1 - F_\\xi(x))}} \\xrightarrow{d} \\xi_{N(0,1)}$$\nTh. Гливенко. Статистика Колмогорова-Смирнова сходится к 0 п.н.\n$$D_n = \\textrm{sup}_{x \\in \\mathbb{R}} |\\hat{F}_n(x) - F_\\xi(x)| \\rightarrow 0$$\nTh. Колмогорова. $F_\\xi(x)$ непрерывна, то при любом $t > 0$\n$$\\textrm{lim}_{n \\rightarrow \\infty} P(\\sqrt{n}D_n \\leq t) = K(t) = \\sum_{j = -\\infty}^{\\infty} (-1)^j \\textrm{exp}(-2j^2t^2)$$\n\n$X_{(k)}$ - $k$-я порядковая статистика.\nАлгоритм отрисовки:\n1) измеряем $\\xi$ $n$ раз: $X_1, ... ,X_n$\n2) отсортировать по неубыванию\n3) рисуем кусочно-постоянную функцию со скачками в $X_{(k)}$ со скачками на $count_i/n$ \n","x":-80,"y":1360,"width":560,"height":1280},
		{"id":"edd328c665651907","type":"text","text":"### S2.\n\n**1.** Распределение $k$-й порядковой статистики. \n$P(X_k < x) = F_\\xi(x)$. \n$$F_{X_{(k)}}(x) = \\sum_{m=k}^n C^m_n F_\\xi^m (x) (1- F_\\xi(x))^{n-m}$$\nПлотность:\n$$C_n^1 f_\\xi(x) C_{n-1}^{k-1} F_\\xi^{k-1}(x)(1-F_\\xi(x))^{n-k}$$\n**2.** \n1) $F_\\xi(x)$ непрерывна, то рспределение $D_n$ не звисит от $F_\\xi(x)$\n2)  $D_n = \\textrm{max}(D_n^+, D_n^-)$\n$D_n^+ = \\textrm{max}_{1 \\leq k \\leq n} (k/n - F_\\xi(X_{(k)})$ , $D_n^- = \\textrm{max}_{1 \\leq k \\leq n} (F_\\xi(X_{(k)}) - (k-1)/n)$ \n3) Если $X_1, ..., X_n \\in U(0,1)$, то $X_{(k)} \\in Beta(k, n-k+1)$ \n\n**3.** Проверка статистических гипотез \n- $H_1$: $N(0,1)$ - простая гипотеза\n- $H_1: N(\\mu, \\sigma^2)$ - сложная гипотеза\n- $H_1: N(0,1). H_2:N(0,2)$\n- $H_1: \\xi_1, \\xi_2$ независимы\n$x_1, ..., x_n \\rightarrow \\lbrace  H_1, ..., H_r \\rbrace$\n$\\Omega$ - выбророчное пространство, $\\delta: \\Omega \\rightarrow \\lbrace  H_1, ..., H_r \\rbrace$ - критерий\n\n|          | что | верно            | на самом деле    |\n| -------- | --- | ---------------- | ---------------- |\n| что      |     | H1               | H2               |\n| выбирает | H1  | +                | ошибка 2-го рода |\n| критерий | H2  | ошибка 1-го рода | +                |\n\n\nВероятность ошибки 1-го рода: $\\alpha = P(\\delta(X) = H_2 | H_1) = P_{H_1}(\\delta(X) = H_2)$\nВероятность ошибки 2-го рода: $\\beta = P(\\delta(X) = H_1 | H_2) = P_{H_2}(\\delta(X) = H_1)$\nВероятность ошибки i-го рода: $\\alpha_i = P_{H_i}(\\delta(X) \\neq H_i)$\n\nКритерий согласия Колмогорова. Дана выборка $x_1, ..., x_n$, непрерывная $F(x)$. Выдвинута гипотеза: $F_\\xi(x) = F(x)$. Составить критерий проверки гипотезы $H_1$ с ошибкой 1-го рода $\\alpha$. \n\nАлгоритм:\n1) составить ЭФР для $x_1, ..., x_n$\n2) вычислить реализацию $D_n$ статистики КС\n3) вычисляется $t_\\alpha$: $P_{H_1}(D_n \\geq t_\\alpha) = \\alpha$\n4) если $D_n \\geq t_\\alpha$ то $H_1$ отклонить, иначе не отклонить\n\nИдея: если гипотеза $H_1$ верна, то $D_n$ должно быть маленьким\n$\\sqrt{n} D_n \\sim K$, $P_{H_1}(K \\geq \\sqrt{n}t_{\\alpha} = \\alpha$, $t_\\alpha = \\frac{1}{\\sqrt{n}}(1 - \\alpha)$ - квантиль распределения $K$","x":480,"y":1360,"width":680,"height":1280},
		{"id":"b31833c9b4f26656","type":"text","text":"#### S3. \n\n\nКритерий согласия $\\chi^2$ Пирсона\nПостановка задачи. Дана с.в. $\\xi$ со значениями $1, ..., N$ с $p_1, ..., p_n$. Имеется выбока $X = (X_1, ..., X_n)$ и вектор вероятностей $p^0 = (p^0_1, ..., p_N^0)$, $0 < p_j^0 < 1$. Гипотеза:\n$$H_1: p = p^0$$\nСоставить критерий проверки $H$ на уровне значимости $\\alpha$.\n\nАлгоритм:\n- Вычислить частоты исходов: \n$$\\nu_j = \\sum_{i=1}^n I(X_i = j)$$\n-  Выислить статистику критерия: \n$$T_{\\chi^2} = \\sum_{j=1}^N \\frac{(\\nu_j - n p_j^0)^2}{np_j^0}$$\n- В качестве критической области (когда отклоняем гипотезу) выбрать $\\Omega_{кр} = \\lbrace x\\in \\Omega |J_{\\chi^2}(x) > t_\\alpha \\rbrace$, где $t_\\alpha$ соответствует условию на уровень значимости $\\alpha$, $P(T_{\\chi^2} > t_\\alpha) \\leq \\alpha$. Известно, что при истинности $H_1$ статистика стремится по распределению к $\\chi^2(N - 1)$, поэтому $t_\\alpha$ вычисляют как $(1-\\alpha)$-квантиль распределения $\\chi^2(N-1)$: \n$$t_\\alpha = \\chi_{1-\\alpha}^2 (N - 1)$$\nЗамечание 1. Критерием пользуются при $n \\geq 50$, $\\nu_j \\geq 5$\nЗамечание 2. Вектор $\\nu = (\\nu_1, ... \\nu_N)$ имеет полиномиальное праспределение $M(n, p_1, ..., p_N)$ с ф.в.\n\n\nКритерий $\\chi^2$ для сложной гипотезы. $H_1: p = p^0(\\theta)$ для $\\theta \\in \\Theta$  ","x":1160,"y":1360,"width":680,"height":1280},
		{"id":"4c895cd1d75fd3cd","type":"text","text":"#### S4.\n$p$-value для проверки гипотез\n$H_1$ - гипотеза, $T(X)$ - статистика критерия, $H_1$ откл. <=> $T(X) > T_\\alpha$, где\n$$t_\\alpha: P_{H_1}(T(X) > t_\\alpha) = \\alpha$$\n$H_1$ отклонить <=> $P_{H_1}(T(X) > T(x)) \\leq \\alpha$. Слева $p$-value. \n","x":1840,"y":1360,"width":740,"height":640},
		{"id":"e67d300831f755c1","type":"text","text":"### Алгоритм проверки гипотез\n\n**1.** Бизнес-задача/бизнес-гипотеза\n**2.** $H_0$, $H_1$ - ставим нулевую и альтернативную гипотезы\n- Пример: сделки $\\xi_i \\sim \\textrm{Bern}(p)$, $H_0$: $p \\leq 0.5$, $H_1$: $p > 0.5$.\n**3.** Выбираем статистику $Q: \\mathcal{X}^n \\rightarrow E$ с известным в условиях $H_0$ распределением \n- Пример: $Q = \\sum_{i=1}^n \\xi_i \\sim Bin(n, p)$. \n**4.** Выбираем уровень статзначимости $\\alpha$ (вероятность ошибки первого рода - $FPR$). Проводим эксперимент, получаем значение $q$ статистики $Q$, считаем $p$-value - вероятность получить значение, настолько же или более редкое, чем $q$. Отвергаем $H_0$, если $p$-value $\\leq \\alpha$.\n$$\\alpha = P(\\delta(X) = H_1 | H_0)$$\n- Пример: $n = 30$, $\\alpha = 0.05$. $q \\geq 19 \\Rightarrow$ отвергаем $H_0$. \n**5.** До запуска эксперимента счиаем $MDE(n, \\textrm{power}, \\alpha)$ \nМощность - вероятность не отвергнуть $H_0$, если верна $H_1$\n$$\\beta = P(\\delta(X) = H_0 | H_1), \\ \\textrm{power} = 1 - \\beta$$\n**6.** Строим доверительный интервал - \n- Пример:\n$\\mu \\in [0.55, 0.87]$","x":-80,"y":2800,"width":580,"height":660},
		{"id":"f458675165d6173a","type":"text","text":"### Доверительный интервал\n\n**Доверительный интервал** - диапазон значений, который с определённой вероятностью (уровнем доверия) содержит истинное значение параметра популяции.\n\n**Уровень доверия** (90%, 95%, 99%). Если проведём эксперимент много раз, то в среднем столько % случаев результат будет лежать в ДИ.\n\nПри известной дисперсии:\n$$\\bar{x} \\pm z \\frac{\\sigma}{\\sqrt{n}}$$\nПри неизвестной дисперсии:\n$$\\bar{x} \\pm t \\frac{s}{\\sqrt{n}}$$","x":500,"y":2800,"width":580,"height":660},
		{"id":"83f51593a4fcd572","type":"text","text":"### Нормальное распределение и Z-тест\n\n**1.** ЦПТ: $E\\xi = \\mu$, $D\\xi = \\sigma^2$ \n$\\sum_{i=1}^n \\xi_i \\xrightarrow{d} N(n\\mu, n\\sigma^2)$ \n$a\\xi_1 + b\\xi_2 \\sim N(a\\mu_1 + b\\mu_2, a^2\\sigma_1^2 + b^2 \\sigma_2^2)$\n$$\\frac{1}{n}\\sum_{i=1}^n \\xi_i = \\bar{\\xi} \\sim N(\\mu, \\sigma^2/n)$$\n$$\\sqrt{n} \\frac{\\bar{\\xi} - \\mu}{\\sigma} \\sim N(0,1)$$\n**2.** Можем перейти от биномиального распредения к нормальному (знаем дисперсию: $p(1-p)$). Но это работает только для достаточно больших $n$, иначе $p$-value занижается\n\n**3. Z-критерий Фишера**\n$H_0$: $\\mu = \\mu_0$ vs. $H_1$: $\\mu > \\mu_0$.\n- Статистика:\n$$ Z(X) = \\sqrt{n} \\frac{\\bar{X} - \\mu_0}{\\sqrt{\\sigma^2}} \\sim_{H_0, \\ n \\rightarrow \\infty} N(0,1)$$\n- Односторонний критерий: $\\lbrace Z(X) \\geq z_{1-\\alpha} \\rbrace$, $p$-value$= 1 - Ф(z)$\n- Двусторонний критерий:  $\\lbrace Z(X) \\geq z_{1-\\alpha/2} \\rbrace \\cup \\lbrace Z(X) \\leq -z_{1-\\alpha/2}  \\rbrace$\n\n**4.** Continuity correction\nСдвинуть cdf вправо на 0.5","x":1080,"y":2800,"width":500,"height":940},
		{"id":"f00f6b913bb01878","type":"text","text":"### Критерии сравнения средних, T-test\n\n**1.**  $\\xi_i$, распределены нормально, но дисперсию не знаем. Хотим работать со средним значением. Заменяем неизвестную $\\sigma^2$ на несмещённую оценку дисперсии:\n$$T =  \\frac{\\bar{x} - \\mu_0}{\\sqrt{\\frac{1/(n-1) \\sum(x_i - \\bar{x}^2)}{n}}} \\sim_{H_0} N(0,1)  \\textrm{ - }T' \\textrm{ тест} $$\nДля небольших $n$ заметны проблемы на концах, поскольку часто может быть занижена оценка для дисперсии\n\n**2.** $X_1, ..., X_n \\sim N(\\mu, \\sigma^2)$. $\\xi_1, ..., \\xi_n \\sim N(0,1)$\n$$\\xi_i = \\frac{X_i - \\mu}{\\sigma}$$\n$$S_\\xi^2 = \\frac{1}{n-1} \\sum(\\frac{X_i - \\mu}{\\sigma} - \\frac{\\bar{X} -\\mu}{\\sigma})^2 = \\frac{1}{\\sigma^2}\\frac{1}{n-1} \\sum_i (X_i - \\bar{X})^2$$\n$$S_X^2 = \\sigma^2 \\frac{1}{n-1}\\sum_{i} (\\xi_i - \\bar{\\xi})^2 \\sim \\chi_{n-1}^2$$\n$$\\frac{(n-1)S_X^2}{\\sigma^2} \\sim \\chi^2_{n-1}$$\nРаспределение Стьюдента:\n$\\xi \\sim N(0,1)$, $\\eta \\sim \\chi^2_{n-1}$\n$$\\frac{\\xi}{\\sqrt{\\eta/(n-1)}} \\sim \\textrm{Student}(n-1)$$\n","x":1580,"y":2800,"width":520,"height":880},
		{"id":"442d34b358bcbd01","type":"text","text":"## Статистика\n- **Вероятностно-статистическое пространство**\n- **Эксперименты** (однократный, многократный, бесконечный)\n- **Статистики и оценки**\nEx. $\\bar{X}, S^2: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ \n","x":138,"y":-3240,"width":470,"height":260},
		{"id":"84e3a4a5d1e20f18","type":"text","text":"### Stats Intro\n$n = 30$, $\\xi_1, ..., \\xi_n \\sim Bern(\\mu)$ => $Q = \\sum_i \\xi_i \\sim Bin(n, \\mu)$\nCDF (cumulative density function):\n$$F_\\xi(x) = P(\\xi \\leq x)$$$F_\\xi(18) = 0.9, F_\\xi(19) = 0.951, F_\\xi(20) = 0.979$\nКвантиль (percent point function): \n$$u_p(\\xi) = \\textrm{inf}\\{x | F_\\xi(x) \\geq p\\}$$\n$u_{0.95}(Q) = 19$\n\n$H_0$: $\\mu \\leq 0.5$, $H_1$: $\\mu > 0.5$. $\\alpha = 0.05$\n$H_0 \\Rightarrow Q \\sim Bin(30, 0.5)$, отвергаем $H_0$ для $q \\geq u_{1 - \\alpha}(Q) + 1 = 20$ \n\np-value: \n$$pval(q) = P_{H_0} (Q \\geq q ) = 1 - P_{H_0}(Q < q) = 1 - P_{H_0}(Q \\leq q-1)$$\n$H_0$ отвергается при результате $q$ <=> $pval(q) \\leq \\alpha$\n\nТ.е., два подхода: 1) для данного $\\alpha$ отвергаем $H_0$ для $q$, начиная с некоторого 2) для данного $q$ отвергаем $H_0$, если p-value $\\leq \\alpha$","x":-1340,"y":2800,"width":620,"height":660},
		{"id":"8d7b3420d1ddaf83","type":"text","text":"### Дополнительные определения\n- Порядковые статистики $X_{(i)}$\n- Эмпирическая функция распределения","x":784,"y":-3240,"width":396,"height":260},
		{"id":"be2d970ecc805e26","type":"text","text":"### Проверка гипотез","x":982,"y":-2880,"width":320,"height":60},
		{"id":"25ceeeec2211f7f1","type":"text","text":"### Параметрические критерии\n- z-тест - проверка гипотез о среднем, когда дисперсия генеральной совокупности известна\n$$z = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}} \\sim_{H_0} N(0,1)$$\n\\* continuity correction\n- t-тест:\nодновыборочный - проверка гипотезы о том, что среднее значение выборки равно $\\mu_0$ \n$$t = \\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}} \\sim_{H_0} t(n-1)$$\n- F-тест:\n$$F = \\frac{s_1^2}{s_2^2}$$\n$s_1^2$, $s_2^2$ - выборочные дисперсии \nЕсли верна $H_0$: $\\sigma_1^2 = \\sigma_2^2$, то статистика имеет $F$-распределение со степенями свободы $f_1 = n_1 - 1$ и $df_2 = n_2 - 1$ \n- Хи-квадрат тест\n$$\\chi^2 = \\sum\\frac{(O_i - E_i)^2}{E_i} \\sim_{H_0} \\chi^2(k-1)$$\n$O_i$ - наблюдаемые частоты, $E_i$ - ожидаемые частоты","x":1440,"y":-2676,"width":500,"height":736},
		{"id":"a477e79745abe650","type":"text","text":"**Мощность** в задаче с тестированием на $Bern(\\mu)$.\nРассматриваем $Bern(0.5)$, $Bern(\\mu)$, строим для них распределение. Вероятность ошибки $FN$ - вероятность того, что при сэмплировании из $Bern(\\mu)$ распределения мы попадём в $1-\\alpha$ квантиль $Bern(0.5)$\nМощность зависит от $\\mu$ (чем больше различие, тем легче детектировать), от размера выборки (распределения будут расплываться меньше, чем разъезжаться :D) \nПри больших $N$ $Bin(\\mu, N) \\sim N(N\\mu, N\\mu(1-\\mu))$\n\n**Минимальный детектируемый эффект** - минимальное отличие параметров распределения, для которого можем обнаружить эффект","x":853,"y":-2000,"width":527,"height":340},
		{"id":"e1e08ce21372b289","type":"text","text":"### Основные концепции\n**1\\.**\n- Нулевая и альтернативная гипотезы $H_0$, $H_1$. \nE.g. $H_0$: $\\mu = \\mu_0$, двусторонняя $H_0$: $\\mu \\neq \\mu_0$, односторонняя $H_0$: $\\mu > \\mu_0$ $(\\mu < \\mu_0)$\n- **Уровень значимости** $\\alpha$ - вероятность отвергнуть нулевую гипотезу, когда она верна (ошибка I рода). Вероятность $FP$ \n\n**2\\.**\n- **p-value** - вероятность получить наблюдаемое значение статистики или более экстремальное при условии, что нулевая гипотеза верна\nОтвергаем $H_0$ <=> $p \\leq \\alpha$\n\n**3\\.**\n- **Ошибка I рода** - $\\alpha$, $FP$\n- **Ошибка II рода** - $\\beta$, $FN$\n- **Мощность критерия** $1 - \\beta$\n\n","x":853,"y":-2700,"width":527,"height":636},
		{"id":"64c99002e2349922","type":"text","text":"### Свойства оценок\n- **Несмещённость**\nДана выборка $X_1, ..., X_n$ из распределения с параметром $\\theta$ (истинное значение). $\\hat{\\theta}: \\mathcal{X}^n \\rightarrow \\Theta$ - оценка $\\theta$. \nОценка несмещённая, если\n$$\\forall \\theta \\ E_{\\mathcal{X}^n}[\\hat{\\theta}] = \\theta$$\nЗдесь $$E[\\hat{\\theta}] = \\int \\hat{\\theta}(x_1, ..., x_n) dF(x_1, ..., x_n)$$\nПример: $\\sum_i (X_i - \\bar{X})^2/n$ - смещённая оценка дисперсии, при раскрытии скобок матожидание применится к $X_i$ \n- **Состоятельность** \n$\\hat{\\theta}$ (сильно) состоятельная, если при увеличении объёма выборки сходится по вероятности к истинной\n$$\\hat{\\theta}(X) \\xrightarrow{P \\ (a.s.)} \\theta$$\nПример: $\\sum_i (X_i - \\bar{X})^2/n$ - состоятельная, т.к. по ЗБЧ\n$$\\sum_i \\frac{1}{n} X_i^2 \\xrightarrow{P} E[X_i^2] = \\sigma^2 + \\mu^2$$\n$$\\bar{X}^2_n \\xrightarrow{P} \\mu^2$$\n$$S^2 \\xrightarrow{P} \\sigma^2$$\n- **Асимптотическая нормальность**\n$\\hat{\\theta}(X_1, ..., X_n)$ а.н.о. $\\theta$, если\n$$\\sqrt{n}(\\hat{\\theta}(X) - \\theta) \\xrightarrow{d_\\theta} N(0, \\Sigma(\\theta))$$\n$$ \\hat{\\theta}(X) \\xrightarrow{d_\\theta} N(\\theta, \\Sigma(\\theta/n)$$\n- **Эффективность** - минимальный variance среди несмещённых         \n","x":-2320,"y":-2376,"width":470,"height":1005},
		{"id":"ac89abd45ab9d3fd","type":"text","text":"### Метод максимального правдоподобия\n$$ L(\\theta | X)  = \\prod_{i=1}^n f(X_i, \\theta); \\ l(\\theta|X) = \\sum_i \\textrm{ln}f(X_i|\\theta)$$\n$$ \\hat{\\theta} = \\textrm{argmax}_\\theta L(\\theta |X) = \\textrm{argmax}_\\theta \\sum_i \\textrm{ln}f(X_i|\\theta)$$\nИдея: найти производную $l(\\theta|X)$, приравнять к 0, найти экстремум, проверить, что максимум\n\nСвойства оценок:\n- Состоятельность\n- Асимптотическая нормальность\n- Эффективность\n- Инвариантноть ($\\hat{\\theta}$ - ОМП для $\\theta$, то для $g(\\theta)$ ОМП будет $g(\\hat{\\theta})$)\n\nНедостатки:\n- Возможная смещённость\n- Может требовать сложных вычислений","x":-1760,"y":-2376,"width":570,"height":625},
		{"id":"d1bc2c06759df07d","type":"text","text":"### Дельта-метод\n\n- **Одномерный случай**\n$\\{X_n\\}$ такая, что\n$$\\sqrt{n}(X_n - \\theta) \\xrightarrow{d}N(0, \\sigma^2)$$\n$g$ дифференцируема в $\\theta$, $g'(\\theta) \\neq 0$. Тогда:\n$$\\sqrt{n}(g(X_n) - g(\\theta)) \\xrightarrow{d} N(0, g'(\\theta)^2\\sigma^2)$$\n- **Многомерный случай**\n$X_n$ - последовательность случайных векторов такая, что \n$$\\sqrt{n}(X_n - \\theta) \\xrightarrow{d} N(0, \\Sigma)$$\n$g$ - дифференцируемая в $\\theta$\n$$\\sqrt{n}(g(X_n) - g(\\theta)) \\xrightarrow{d}N(0, \\nabla g^T(\\theta) \\Sigma \\nabla g(\\theta))$$\n\nПрименение:\n- Оценка дисперсии сложных статистик\n- Построение доверительных интервалов\n- Анализ нелинейных моделей","x":-1760,"y":-1701,"width":570,"height":660},
		{"id":"fb1d22c9bc485d56","type":"text","text":"### Точечные оценки","x":-1285,"y":-2571,"width":277,"height":66},
		{"id":"fa095e4c883af555","type":"text","text":"### Метод моментов\nТеоретические моменты для с.в. с $f(x | \\theta)$: \n$$ \\mu_k  = E[X^k]$$\nВыборочные моменты ($X_1, ..., X_n$):\n$$m_k = \\frac{1}{n} \\sum_{i=1}^n X_i^k$$\nАлгоритм: \n1) Записать теоретические моменты $\\mu_k(\\theta)$\n2) Вычислить выборочные моменты $m_k$\n3) Приравнять теоретические и выборочные: $\\mu_k(\\theta) = m_k$\n4) Решить систему уравнений\n\nПреимущества:\n- Простота идеи\n- Универсальность\nНедостатки:\n- Система может оказаться сложной\n- Оценки могут быть хуже, чем полученные с помощью ОМП","x":-1146,"y":-2376,"width":626,"height":625},
		{"id":"1941dd773c2f2bc9","type":"text","text":"### Оценивание параметров","x":-1122,"y":-2811,"width":366,"height":55},
		{"id":"f60bde881e43ff00","type":"text","text":"### Интервальные оценки\nМетоды построения интервалов, которые с заданной вероятностью (уровнем доверия) содержат истинное значение параметра\n\n","x":-160,"y":-2571,"width":840,"height":151},
		{"id":"bb55c11b6e944672","type":"text","text":"### Доверительный интервал\n\nТам, где нулевая гипотеза об оценке не отвергается с заданной вероятностью \n\n- Известная дисперсия:\n$$\\bar{X} \\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}$$\n(ЦПТ => $\\bar{X} \\sim N(\\mu, \\sigma^2 /n)$\n- Неизвестная дисперсия\n$$\\bar{X} \\pm t_{\\alpha/2, n-1}\\frac{S}{\\sqrt{n}}$$\n($\\sigma$ неизвестно => $\\frac{\\bar{X} - \\mu}{S/\\sqrt{n}} \\sim t(n-1)$)\n- ДИ для дисперсии (нормальное распределение)\n$$(\\frac{(n-1)S^2}{\\chi^2_{\\alpha/2, n - 1}}, \\frac{(n-1)S^2}{\\chi_{1-\\alpha/2, n-1}})$$\n\n","x":-480,"y":-2300,"width":540,"height":600},
		{"id":"ea1c8d15fbc03dad","type":"text","text":"### Метод Монте-Карло\nПример: двухвыборочный T-тест, проверяем, работает ли на малыхччччччч выборках. Делаем выборку из распределения, запускаем T-тест. Если тест сказал, что $H_0: EA = EB$ отвергается, то это ошибка вида $FP$. Их доля для большого количества экспериментов должна быть равна $\\alpha$ ","x":1400,"y":-3760,"width":606,"height":276},
		{"id":"8e4bb6d88fb03b91","type":"text","text":"### Непараметрические критерии","x":2200,"y":-2676,"width":492,"height":103},
		{"id":"f99b40b0b9077b0b","type":"text","text":"### Критерии согласия\n$\\xi_1, ..., \\xi_n \\sim \\mathcal{P}$\n$H_0: \\mathcal{P} = \\mathcal{P}_0$, $H_0: \\xi_1, ..., \\xi_n \\sim N(0,1)$ - простая гипотеза\n$H: \\mathcal{P} \\in \\mathcal{P}_\\theta$, $H_0: \\xi_1, ..., \\xi_n \\sim  N(\\theta)$ - сложная гипотеза\n\n\n  ","x":2136,"y":-2480,"width":504,"height":172},
		{"id":"c953485b2dd3d307","type":"text","text":"### Критерий Колмогорова\nПроверка простой гипотезы\n$H_0$: $\\mathcal{P} = \\mathcal{P}_0$ <=> $F = F_0$\n\nТребования: $X_i$ i.i.d., $F_X$ непрерывны; для $Y$ аналогично\nЭФР:\n$$\\hat{F} (x) = \\frac{\\sum_{i=1}^n [X_i \\leq x]}{n} \\xrightarrow{P \\ (a.s.)} F(x) $$\n$$ D_n = \\sup_{x \\in \\mathbb{R}} |\\hat{F}(x) - F(x)| \\rightarrow 0 $$\n$$\\sqrt{n}D_n \\sim_{H_0} \\varphi $$\n$\\varphi$ - распределение Колмогорова \n\nЕсли оцениваем параметры по выборке ($\\mu$, $S^2),$\nто нужна поправка Лиллиефорса","x":2020,"y":-2200,"width":440,"height":580},
		{"id":"187b6a02f2c93ce0","type":"text","text":"### Критерий Шапиро-Уилка\nСложная гипотеза\n$$ W = \\frac{(\\sum_{i=1}^n a_{n-i+1}(x_{n-i+1}-x_i))^2}{\\sum_{i=1}^n (x_i -\\bar{x})^2}$$","x":2020,"y":-1560,"width":440,"height":202},
		{"id":"46f6889979209c5f","type":"text","text":"### Критерии однородности\n$X_1, ..., X_n \\sim \\mathcal{F}_X$, $Y_1, ..., Y_n \\sim \\mathcal{F}_Y$ \n$H_0: \\mathcal{F}_X = \\mathcal{F}_Y$\n$H_0: \\mathcal{F}_X \\neq \\mathcal{F}_Y$\n","x":2692,"y":-2480,"width":468,"height":172},
		{"id":"8dc8170e2cee36ae","type":"text","text":"### Критерий хи-квадрат Пирсона\n\nПростая гипотеза согласия\n 1\\. Фиксируем $\\alpha$. дискретное распределение $\\mathcal{P}$, выборку с $k$ исходами в виде frequency table. Если в ячейчке $<5$, то объединяем исходы, пока условие не выполнено\nСтатистика\n$$\\tau = n \\sum_{i=1}^k \\frac{(n_i / n - p_i)^2}{p_i} \\sim \\chi_{k-1}^2$$\nЕсли p-value $\\leq \\alpha$, то отвергаем гипотезу \n\n2\\. Для случая непрерывного распределения разбиваем область определения на несколько частей и применяем критерий (оценка эффективности с помощью Монте-Карло)\n\n3\\. Проверка сложной гипотезы\nСперва оцениваем параметры распределения (ОМП)\n$$\\tau_v \\sim \\chi^2_{k-1-v}$$\n4\\. Проверка гипотезы о непрерывности\n$\\xi$, $\\eta$ \nТаблица сопряжённости $n_{ij}$ - то,  насколько часто $a_i$ сопряжено с $b_j$\n$H_0: P(a_i b_j) = P(a_i)P(b_j)$\n$$n \\sum_{i,j} (\\frac{n_{ij}}{n} - \\hat{p}_i\\hat{q}_j )^2 / \\hat{p}_i \\hat{q}_j$$\n5\\. Проверка гипотезы однородности\nПример: рассматриваем таблицу количество обмороков / применение лекарства как таблицу сопряжённости\n\n6\\. Поправка Йейтса\n$$n \\sum_{i,j} (\\frac{n_{ij}}{n} - \\hat{p}_i\\hat{q}_j - 0.5)^2 / \\hat{p}_i \\hat{q}_j$$","x":2580,"y":-1540,"width":640,"height":900},
		{"id":"fc715282c22557bf","type":"text","text":"### Критерий Манна-Уитни\n\nПример. Два нормальных распределения. Рассматриваем множество пар ($A_i, B_j$) s.t. $B_i > A_j$. $MN/2$, если верна $H_0$  ","x":3400,"y":-1580,"width":640,"height":222},
		{"id":"c807ecebe500fe98","type":"text","text":"### Бутстрап\n\n1\\. \nПроизвольые характеристики генеральной совокупности\nНапример, $X_{[0.75]}$\n$\\Delta := \\hat{\\theta} - \\theta$ \nИз $\\xi$ сэмплируем много выборок $X_i$ (e.g. 10k). Получаем по каждой из выборок $\\Delta_i$. $\\Delta_{2.5\\%} \\approx \\Delta_{(250)}$,  $\\Delta_{97.5\\%} \\approx \\Delta_{(9750)}$\n$$\\theta \\in (\\hat{\\theta} - \\Delta_{97.5\\%},\\hat{\\theta} - \\Delta_{2.5\\%} )$$\nПусть есть одна выборка\n$$\\hat{cdf}_{\\xi^*}(x) = \\frac{1}{n} \\sum_{i=1}^n [x \\geq X_i]$$\nИз $\\xi^*$ порождаем $X_1^*$, ..., $X_{10000}^*$. Это эквивалентно выбору с возвращением из исходной выборки \n\nАлгоритм:\n1. Считаем $\\hat{\\theta}$ по изначальной выборке\n2. Пишем генерацию выборок из эмпирического распределения\n3. Пишем генерацию $\\theta^*$ \n4. Считаем левый и правый квантили\n5. Считаем $CI$ \n\n2\\. Двухвыборочный бутстрап\nЕсть две выборки $X$. $Y$ \n$\\theta = \\theta_X - \\theta_Y$. $X_1^*, Y_1^*$. $\\theta_1^* = \\hat{\\theta}(X_1^*) - \\theta_Y(Y_1^*)$, ... $_{10000}$  \n\n3\\. Виды доверительных интервалов бутстрапа\n$$\\theta \\in (\\hat{\\theta} \\pm 2 \\sqrt{S^2_{\\hat{\\theta^*}}})$$","x":-990,"y":-1500,"width":510,"height":920},
		{"id":"ee0d185dd9e61345","type":"text","text":"### Основы описательной статистики\n\n1\\. Генеральная совокупность - всё множество объектов, о котором хотим делать выводы. Выборка - подмножество, на основе которого хотим делать выводы\n\n2\\. Разница между средним, медианой, модой. Что и когда лучше использовать\n- Среднее \n$$EX = \\int_\\Omega X(\\omega) P(d\\omega) \\ \\Big | \\ \\int_\\mathbb{R} x dF_X(x) \\ \\Big | \\sum_{x \\in \\textrm{Im}X} xp(x) \\ \\Big| \\ \\int_\\mathbb{R} x \\rho(x)dx$$\n- Медиана\na) центральная порядковая статистика | полусумма левой и правой ближайших к центру\n$$x_{(n+1)/2} \\ \\big | \\ \\frac{x_{(n/2)} + x_{((n/2)+1)}}{2}$$\nб) значение, слева и справа от которого лежит половина вероятностной меры (1/2 квантиль)\n$$\\lim_{x \\rightarrow m-} F(x) \\leq \\frac{1}{2} \\leq F(m)$$\n- Мода - значение, которое встречается чаще всего | максимум плотности распределения\n\n|Мера|Когда использовать|Примеры|\n|---|---|---|\n|**Среднее (mean)**|Когда данные симметричны, нет сильных выбросов.|Рост людей, результаты экзамена.|\n|**Медиана (median)**|Когда данные перекошены (skewed), есть выбросы.|Доход населения, цена жилья.|\n|**Мода (mode)**|Когда интересует наиболее частое значение. Особенно полезна для категориальных данных.|Любимый цвет, чаще всего покупаемый товар.|\n\n3\\. Дисперсия и стандартное отклонение\n\n$$DX = E(X- EX)^2 = EX^2 - (EX)^2, \\ \\textrm{std}X = \\sqrt{DX}$$\n4\\. Выбросы и как с ними бороться?\nВыбросы - значения, значительно отличающиеся от других в выборке\nЧто делать - зависит от контекста. Можно удалить, если ошибка, можно заменить, можно оставить (если информативен)\n\n5\\. Квантиль, квартиль и персентиль\n- Квантиль\n$$Q_X(p) = \\inf \\lbrace x \\in \\mathbb{R} \\ | \\ F_X(x) = p \\rbrace$$\n- Квартиль: квантили 1/4, 1/2, 3/4\n- Персентиль: квантили $[0.01, 0.02, ..., 0.99]$","x":-4480,"y":-3060,"width":860,"height":1180},
		{"id":"e848158e72e9f1d9","type":"text","text":"## Вопросы к собеседованию\n","x":-4480,"y":-3121,"width":409,"height":61},
		{"id":"d2e1dc11c6c8e64e","type":"text","text":"### Распределения\n\n6\\. Нормальное распределение\n7\\. Биномиальное, пуассоновское, экспоненциальное\n8\\. ЗБЧ,  ЦПТ\n\n","x":-3620,"y":-3060,"width":940,"height":1180},
		{"id":"1e82dcd1d83cb7d0","type":"text","text":"### Критерий Колмогорова-Смирнова \n\n$$\\hat{F}_X (x) = \\frac{\\sum_{i=1}^n [X_i \\leq x]}{n}, \\hat{F}_Y (x) = \\frac{\\sum_{i=1}^n [Y_i \\leq x]}{n} $$\n$$D_{mn} = \\sup_x |\\hat{F}_X(x) - \\hat{F}_Y(x)|$$\nПри $H_0$:\n$$\\sqrt\\frac{nm}{m+n} \\xrightarrow{d} \\phi$$,\n$\\phi$ - распределение Колмогорова\n\nРазмер выборки $m, n \\geq 20$ ","x":2600,"y":-2160,"width":537,"height":540}
	],
	"edges":[
		{"id":"5d79df55a469b3e9","fromNode":"fb1d22c9bc485d56","fromSide":"bottom","toNode":"ac89abd45ab9d3fd","toSide":"top"},
		{"id":"fdaa5eefc1882628","fromNode":"fb1d22c9bc485d56","fromSide":"bottom","toNode":"fa095e4c883af555","toSide":"top"},
		{"id":"4e54b4cdec8804bd","fromNode":"fb1d22c9bc485d56","fromSide":"bottom","toNode":"64c99002e2349922","toSide":"top"},
		{"id":"7fbb2f9b5864e251","fromNode":"442d34b358bcbd01","fromSide":"bottom","toNode":"1941dd773c2f2bc9","toSide":"top"},
		{"id":"e93b391224562a27","fromNode":"1941dd773c2f2bc9","fromSide":"bottom","toNode":"fb1d22c9bc485d56","toSide":"top"},
		{"id":"8dee7616a4df020b","fromNode":"442d34b358bcbd01","fromSide":"right","toNode":"8d7b3420d1ddaf83","toSide":"left"},
		{"id":"e4638db1d2844afd","fromNode":"fb1d22c9bc485d56","fromSide":"bottom","toNode":"d1bc2c06759df07d","toSide":"top"},
		{"id":"ec91ebb29bd03b21","fromNode":"442d34b358bcbd01","fromSide":"bottom","toNode":"be2d970ecc805e26","toSide":"top"},
		{"id":"c97ab22abe36716b","fromNode":"be2d970ecc805e26","fromSide":"bottom","toNode":"e1e08ce21372b289","toSide":"top"},
		{"id":"3180ab2e5b9f0540","fromNode":"be2d970ecc805e26","fromSide":"bottom","toNode":"25ceeeec2211f7f1","toSide":"top"},
		{"id":"bb0c82f538762d15","fromNode":"e1e08ce21372b289","fromSide":"bottom","toNode":"a477e79745abe650","toSide":"top"},
		{"id":"51da9046d1c75fe4","fromNode":"1941dd773c2f2bc9","fromSide":"bottom","toNode":"f60bde881e43ff00","toSide":"top"},
		{"id":"bd919f5af09d7cc3","fromNode":"f60bde881e43ff00","fromSide":"bottom","toNode":"bb55c11b6e944672","toSide":"top"},
		{"id":"5af470d0d2bdd587","fromNode":"442d34b358bcbd01","fromSide":"top","toNode":"ea1c8d15fbc03dad","toSide":"top"},
		{"id":"4a79cb342164b63c","fromNode":"be2d970ecc805e26","fromSide":"bottom","toNode":"8e4bb6d88fb03b91","toSide":"top"},
		{"id":"711836afcfcdee5e","fromNode":"8e4bb6d88fb03b91","fromSide":"bottom","toNode":"f99b40b0b9077b0b","toSide":"top"},
		{"id":"92436a8457b0cf68","fromNode":"f99b40b0b9077b0b","fromSide":"bottom","toNode":"c953485b2dd3d307","toSide":"top"},
		{"id":"47933aa7b13ffbad","fromNode":"c953485b2dd3d307","fromSide":"bottom","toNode":"187b6a02f2c93ce0","toSide":"top"},
		{"id":"634e16d446de2e21","fromNode":"8e4bb6d88fb03b91","fromSide":"bottom","toNode":"46f6889979209c5f","toSide":"top"},
		{"id":"18f89450dc78f8b5","fromNode":"46f6889979209c5f","fromSide":"bottom","toNode":"1e82dcd1d83cb7d0","toSide":"top"},
		{"id":"d70a864850730b5f","fromNode":"f99b40b0b9077b0b","fromSide":"bottom","toNode":"8dc8170e2cee36ae","toSide":"top"},
		{"id":"ef1803543af118a9","fromNode":"46f6889979209c5f","fromSide":"bottom","toNode":"fc715282c22557bf","toSide":"top"},
		{"id":"6b4353b8ede0710a","fromNode":"46f6889979209c5f","fromSide":"bottom","toNode":"8dc8170e2cee36ae","toSide":"top"}
	]
}